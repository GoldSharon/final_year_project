{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc5f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Test Decision Tree Regressor with Optuna Hyperparameter Optimization\n",
    "# =====================================================================\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import optuna\n",
    "# from sklearn.datasets import load_diabetes, make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# # Assuming your DecisionTreeRegressor is importable\n",
    "# from lightning_ml.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# def suggest_decision_tree_regressor_params(trial):\n",
    "#     \"\"\"Decision Tree Regressor - Optuna parameter suggestions\"\"\"\n",
    "#     use_max_depth = trial.suggest_categorical('use_max_depth', [True, False])\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 30) if use_max_depth else None\n",
    "    \n",
    "#     return {\n",
    "#         'max_depth': max_depth,\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "#         'max_features': trial.suggest_categorical('max_features', [None, 'sqrt', 'log2']),\n",
    "#         'criterion': trial.suggest_categorical('criterion', ['mae', 'mse']),  \n",
    "#         'random_state': 42,\n",
    "#         'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     }\n",
    "\n",
    "\n",
    "# def objective(trial, X_train, X_val, y_train, y_val, DecisionTreeRegressor):\n",
    "#     \"\"\"\n",
    "#     Objective function for Optuna optimization.\n",
    "    \n",
    "#     Args:\n",
    "#         trial: Optuna trial object\n",
    "#         X_train, X_val: Training and validation features\n",
    "#         y_train, y_val: Training and validation targets\n",
    "#         DecisionTreeRegressor: Your model class\n",
    "        \n",
    "#     Returns:\n",
    "#         Validation score (negative MSE for minimization)\n",
    "#     \"\"\"\n",
    "#     # Get hyperparameters from trial\n",
    "#     params = suggest_decision_tree_regressor_params(trial)\n",
    "    \n",
    "#     try:\n",
    "#         # Create and train model\n",
    "#         model = DecisionTreeRegressor(**params)\n",
    "#         model.fit(X_train, y_train, verbose=False)\n",
    "        \n",
    "#         # Evaluate on validation set\n",
    "#         y_pred = model.predict(X_val)\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         mse = mean_squared_error(y_val, y_pred)\n",
    "#         r2 = r2_score(y_val, y_pred)\n",
    "#         mae = mean_absolute_error(y_val, y_pred)\n",
    "        \n",
    "#         # Store additional metrics in trial\n",
    "#         trial.set_user_attr('r2_score', r2)\n",
    "#         trial.set_user_attr('mae', mae)\n",
    "#         trial.set_user_attr('tree_depth', model.get_depth())\n",
    "#         trial.set_user_attr('n_leaves', model.get_n_leaves())\n",
    "        \n",
    "#         # Return MSE (Optuna minimizes by default)\n",
    "#         return mse\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Trial failed with error: {e}\")\n",
    "#         # Return a large value to indicate failure\n",
    "#         return float('inf')\n",
    "\n",
    "\n",
    "# def run_optuna_optimization(DecisionTreeRegressor, \n",
    "#                             n_trials=50, \n",
    "#                             dataset='diabetes',\n",
    "#                             test_size=0.2,\n",
    "#                             val_size=0.2):\n",
    "#     \"\"\"\n",
    "#     Run Optuna hyperparameter optimization for Decision Tree Regressor.\n",
    "    \n",
    "#     Args:\n",
    "#         DecisionTreeRegressor: Your model class\n",
    "#         n_trials: Number of optimization trials\n",
    "#         dataset: 'diabetes' or 'synthetic'\n",
    "#         test_size: Test set proportion\n",
    "#         val_size: Validation set proportion (from training data)\n",
    "        \n",
    "#     Returns:\n",
    "#         Dictionary with optimization results\n",
    "#     \"\"\"\n",
    "#     print(\"=\" * 70)\n",
    "#     print(\"Decision Tree Regressor - Optuna Hyperparameter Optimization\")\n",
    "#     print(\"=\" * 70)\n",
    "    \n",
    "#     # Load dataset\n",
    "#     if dataset == 'diabetes':\n",
    "#         data = load_diabetes()\n",
    "#         X, y = data.data, data.target\n",
    "#         print(f\"\\nDataset: Diabetes (n_samples={len(X)}, n_features={X.shape[1]})\")\n",
    "#     else:\n",
    "#         X, y = make_regression(n_samples=1000, n_features=20, \n",
    "#                                n_informative=15, noise=10, random_state=42)\n",
    "#         print(f\"\\nDataset: Synthetic (n_samples={len(X)}, n_features={X.shape[1]})\")\n",
    "    \n",
    "#     # Split data: Train / Val / Test\n",
    "#     X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "#         X, y, test_size=test_size, random_state=42\n",
    "#     )\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(\n",
    "#         X_temp, y_temp, test_size=val_size, random_state=42\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Train samples: {len(X_train)}\")\n",
    "#     print(f\"Validation samples: {len(X_val)}\")\n",
    "#     print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "#     # Create Optuna study\n",
    "#     print(f\"\\nStarting optimization with {n_trials} trials...\")\n",
    "#     study = optuna.create_study(\n",
    "#         direction='minimize',  # Minimize MSE\n",
    "#         study_name='decision_tree_regressor_optimization',\n",
    "#         sampler=optuna.samplers.TPESampler(seed=42)\n",
    "#     )\n",
    "    \n",
    "#     # Run optimization\n",
    "#     study.optimize(\n",
    "#         lambda trial: objective(trial, X_train, X_val, y_train, y_val, DecisionTreeRegressor),\n",
    "#         n_trials=n_trials,\n",
    "#         show_progress_bar=True\n",
    "#     )\n",
    "    \n",
    "#     # Get best parameters\n",
    "#     best_params = study.best_params\n",
    "#     best_value = study.best_value\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 70)\n",
    "#     print(\"OPTIMIZATION RESULTS\")\n",
    "#     print(\"=\" * 70)\n",
    "#     print(f\"\\nBest Validation MSE: {best_value:.4f}\")\n",
    "#     print(f\"\\nBest Parameters:\")\n",
    "#     for param, value in best_params.items():\n",
    "#         print(f\"  {param}: {value}\")\n",
    "    \n",
    "#     # Get additional metrics from best trial\n",
    "#     best_trial = study.best_trial\n",
    "#     print(f\"\\nBest Trial Additional Metrics:\")\n",
    "#     print(f\"  R² Score: {best_trial.user_attrs.get('r2_score', 'N/A'):.4f}\")\n",
    "#     print(f\"  MAE: {best_trial.user_attrs.get('mae', 'N/A'):.4f}\")\n",
    "#     print(f\"  Tree Depth: {best_trial.user_attrs.get('tree_depth', 'N/A')}\")\n",
    "#     print(f\"  Number of Leaves: {best_trial.user_attrs.get('n_leaves', 'N/A')}\")\n",
    "    \n",
    "#     # Train final model with best parameters\n",
    "#     print(\"\\n\" + \"=\" * 70)\n",
    "#     print(\"FINAL MODEL EVALUATION\")\n",
    "#     print(\"=\" * 70)\n",
    "    \n",
    "#     # Prepare best params for model initialization\n",
    "#     final_params = best_params.copy()\n",
    "#     if 'use_max_depth' in final_params:\n",
    "#         del final_params['use_max_depth']\n",
    "    \n",
    "#     final_model = DecisionTreeRegressor(**final_params)\n",
    "    \n",
    "#     # Train on combined train+val data\n",
    "#     X_train_full = np.vstack([X_train, X_val])\n",
    "#     y_train_full = np.concatenate([y_train, y_val])\n",
    "    \n",
    "#     print(\"\\nTraining final model on combined train+val data...\")\n",
    "#     final_model.fit(X_train_full, y_train_full, verbose=True)\n",
    "    \n",
    "#     # Evaluate on test set\n",
    "#     y_pred_test = final_model.predict(X_test)\n",
    "#     test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "#     test_r2 = r2_score(y_test, y_pred_test)\n",
    "#     test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "#     test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "#     print(f\"\\nTest Set Performance:\")\n",
    "#     print(f\"  MSE:  {test_mse:.4f}\")\n",
    "#     print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "#     print(f\"  MAE:  {test_mae:.4f}\")\n",
    "#     print(f\"  R²:   {test_r2:.4f}\")\n",
    "    \n",
    "#     # Feature importances\n",
    "#     print(f\"\\nTop 5 Feature Importances:\")\n",
    "#     importances = final_model.feature_importances_\n",
    "#     top_indices = np.argsort(importances)[-5:][::-1]\n",
    "#     for idx in top_indices:\n",
    "#         print(f\"  Feature {idx}: {importances[idx]:.4f}\")\n",
    "    \n",
    "#     # Return results\n",
    "#     return {\n",
    "#         'study': study,\n",
    "#         'best_params': best_params,\n",
    "#         'best_validation_mse': best_value,\n",
    "#         'final_model': final_model,\n",
    "#         'test_metrics': {\n",
    "#             'mse': test_mse,\n",
    "#             'rmse': test_rmse,\n",
    "#             'mae': test_mae,\n",
    "#             'r2': test_r2\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "\n",
    "# def plot_optimization_history(study):\n",
    "#     \"\"\"\n",
    "#     Plot optimization history (requires plotly).\n",
    "    \n",
    "#     Args:\n",
    "#         study: Optuna study object\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         import plotly.graph_objects as go\n",
    "        \n",
    "#         # Create figure\n",
    "#         fig = go.Figure()\n",
    "        \n",
    "#         # Add optimization history\n",
    "#         trials = study.trials\n",
    "#         values = [trial.value for trial in trials if trial.value != float('inf')]\n",
    "        \n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             y=values,\n",
    "#             mode='lines+markers',\n",
    "#             name='Trial MSE',\n",
    "#             line=dict(color='blue', width=2),\n",
    "#             marker=dict(size=6)\n",
    "#         ))\n",
    "        \n",
    "#         # Add best value line\n",
    "#         best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             y=best_values,\n",
    "#             mode='lines',\n",
    "#             name='Best MSE',\n",
    "#             line=dict(color='red', width=2, dash='dash')\n",
    "#         ))\n",
    "        \n",
    "#         fig.update_layout(\n",
    "#             title='Optimization History',\n",
    "#             xaxis_title='Trial',\n",
    "#             yaxis_title='MSE',\n",
    "#             hovermode='x unified'\n",
    "#         )\n",
    "        \n",
    "#         fig.show()\n",
    "        \n",
    "#     except ImportError:\n",
    "#         print(\"Plotly not available for visualization\")\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Import your DecisionTreeRegressor\n",
    "#     # from lightning_ml.decision_tree import DecisionTreeRegressor\n",
    "    \n",
    "#     # For demonstration, we'll assume it's available\n",
    "#     # Replace this with your actual import\n",
    "\n",
    "    \n",
    "#     # Uncomment below to run optimization\n",
    "\n",
    "#     results = run_optuna_optimization(\n",
    "#         DecisionTreeRegressor=DecisionTreeRegressor,\n",
    "#         n_trials=10,\n",
    "#         dataset='diabetes',\n",
    "#         test_size=0.2,\n",
    "#         val_size=0.2\n",
    "#     )\n",
    "    \n",
    "#     # Optionally plot optimization history\n",
    "#     plot_optimization_history(results['study'])\n",
    "    \n",
    "#     # Access results\n",
    "#     print(\"\\nOptimization Complete!\")\n",
    "#     print(f\"Best validation MSE: {results['best_validation_mse']:.4f}\")\n",
    "#     print(f\"Test R² score: {results['test_metrics']['r2']:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846d266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
