{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120644c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:37:22,950] A new study created in memory with name: no-name-8fbafed6-b214-47da-be04-af5e88490355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚ö° LIGHTNING ML - HYPERPARAMETER OPTIMIZATION\n",
      "======================================================================\n",
      "Running Optuna hyperparameter tuning for all models...\n",
      "\n",
      "======================================================================\n",
      "üîç REGRESSION MODELS - HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: LinearRegression\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a797235b9617429f8970410db82b256c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:37:24,313] A new study created in memory with name: no-name-34899789-36ea-4dd0-bf1a-3b326461c43b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:37:24,233] Trial 0 finished with value: -4.277644824214061 and parameters: {'fit_intercept': False}. Best is trial 0 with value: -4.277644824214061.\n",
      "[I 2025-10-07 19:37:24,246] Trial 1 finished with value: 0.4526029062055733 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,254] Trial 2 finished with value: 0.4526029062055733 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,261] Trial 3 finished with value: -4.277644824214061 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,267] Trial 4 finished with value: -4.277644824214061 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,275] Trial 5 finished with value: -4.277644824214061 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,282] Trial 6 finished with value: 0.4526029062055733 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,291] Trial 7 finished with value: -4.277644824214061 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,296] Trial 8 finished with value: -4.277644824214061 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.4526029062055733.\n",
      "[I 2025-10-07 19:37:24,304] Trial 9 finished with value: 0.4526029062055733 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.4526029062055733.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ LinearRegression Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.4526\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ fit_intercept: True\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.4526\n",
      "  ‚Ä¢ MSE: 2900.1929\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: RidgeRegression\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e4cb719c54fba9fb920078dce9c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:38:02,392] Trial 0 finished with value: 0.29397378336612734 and parameters: {'alpha': 0.0745934328572655, 'epochs': 500, 'lr': 0.015702970884055395, 'batch_size': 16, 'optimizer': 'adam'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:06,556] Trial 1 finished with value: -1.853561770774018 and parameters: {'alpha': 0.001267425589893723, 'epochs': 500, 'lr': 0.03142880890840111, 'batch_size': 128, 'optimizer': 'adam'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:07,861] Trial 2 finished with value: -0.5572912814803299 and parameters: {'alpha': 1.1462107403425035, 'epochs': 100, 'lr': 0.0007523742884534858, 'batch_size': 64, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:10,297] Trial 3 finished with value: -1.8010020452948354 and parameters: {'alpha': 1.0907475835157696, 'epochs': 100, 'lr': 0.00015673095467235422, 'batch_size': 32, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:19,559] Trial 4 finished with value: -0.13641789542098048 and parameters: {'alpha': 0.00407559644007287, 'epochs': 250, 'lr': 0.00012681352169084607, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:24,948] Trial 5 finished with value: -0.14205275382504823 and parameters: {'alpha': 70.45683638454501, 'epochs': 400, 'lr': 0.06584106160121614, 'batch_size': 64, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:27,239] Trial 6 finished with value: -2.419710140061975 and parameters: {'alpha': 0.08777815504719653, 'epochs': 150, 'lr': 0.030634622106220845, 'batch_size': 64, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:31,543] Trial 7 finished with value: -1.4825918907682913 and parameters: {'alpha': 7.264803074826735, 'epochs': 100, 'lr': 0.00010388823104027947, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:34,388] Trial 8 finished with value: -0.07931278979835277 and parameters: {'alpha': 20.67840939783948, 'epochs': 350, 'lr': 0.0009833181933644897, 'batch_size': 128, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29397378336612734.\n",
      "[I 2025-10-07 19:38:44,913] Trial 9 finished with value: -0.6618457676574159 and parameters: {'alpha': 0.00396251783257234, 'epochs': 400, 'lr': 0.019158219548093176, 'batch_size': 32, 'optimizer': 'adam'}. Best is trial 0 with value: 0.29397378336612734.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:39:14,187] A new study created in memory with name: no-name-385290d1-337b-4fc7-98ac-ee660965bec7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ RidgeRegression Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.2940\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ alpha: 0.0745934328572655\n",
      "  ‚Ä¢ epochs: 500\n",
      "  ‚Ä¢ lr: 0.015702970884055395\n",
      "  ‚Ä¢ batch_size: 16\n",
      "  ‚Ä¢ optimizer: adam\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.2928\n",
      "  ‚Ä¢ MSE: 3746.7400\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: LassoRegression\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80757d90be394822b44f8e6b599821a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:39:41,281] Trial 0 finished with value: 0.29072790527784664 and parameters: {'alpha': 0.0745934328572655, 'epochs': 500, 'lr': 0.015702970884055395, 'batch_size': 16, 'optimizer': 'adam'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:39:47,055] Trial 1 finished with value: -1.8519591598800962 and parameters: {'alpha': 0.001267425589893723, 'epochs': 500, 'lr': 0.03142880890840111, 'batch_size': 128, 'optimizer': 'adam'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:39:48,746] Trial 2 finished with value: -0.5598507654381542 and parameters: {'alpha': 1.1462107403425035, 'epochs': 100, 'lr': 0.0007523742884534858, 'batch_size': 64, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:39:51,364] Trial 3 finished with value: -1.8094531603416342 and parameters: {'alpha': 1.0907475835157696, 'epochs': 100, 'lr': 0.00015673095467235422, 'batch_size': 32, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:40:03,649] Trial 4 finished with value: -0.13591299021686676 and parameters: {'alpha': 0.00407559644007287, 'epochs': 250, 'lr': 0.00012681352169084607, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:40:10,667] Trial 5 finished with value: -0.1441024280854728 and parameters: {'alpha': 70.45683638454501, 'epochs': 400, 'lr': 0.06584106160121614, 'batch_size': 64, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:40:13,462] Trial 6 finished with value: -2.4262582984529657 and parameters: {'alpha': 0.08777815504719653, 'epochs': 150, 'lr': 0.030634622106220845, 'batch_size': 64, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:40:18,395] Trial 7 finished with value: -1.4836297174513655 and parameters: {'alpha': 7.264803074826735, 'epochs': 100, 'lr': 0.00010388823104027947, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:40:21,798] Trial 8 finished with value: -0.07995203513932214 and parameters: {'alpha': 20.67840939783948, 'epochs': 350, 'lr': 0.0009833181933644897, 'batch_size': 128, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.29072790527784664.\n",
      "[I 2025-10-07 19:40:34,828] Trial 9 finished with value: -0.6556778893209303 and parameters: {'alpha': 0.00396251783257234, 'epochs': 400, 'lr': 0.019158219548093176, 'batch_size': 32, 'optimizer': 'adam'}. Best is trial 0 with value: 0.29072790527784664.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:41:01,830] A new study created in memory with name: no-name-a7470ee4-7417-4de6-a676-10ad021f999c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ LassoRegression Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.2907\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ alpha: 0.0745934328572655\n",
      "  ‚Ä¢ epochs: 500\n",
      "  ‚Ä¢ lr: 0.015702970884055395\n",
      "  ‚Ä¢ batch_size: 16\n",
      "  ‚Ä¢ optimizer: adam\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.2898\n",
      "  ‚Ä¢ MSE: 3762.5241\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: SVMRegressor\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720222e2141a4472b8d2eb79f1b676cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:41:08,155] Trial 0 finished with value: -4.010839262947069 and parameters: {'kernel': 'rbf', 'C': 0.2938027938703535, 'epsilon': 0.020511104188433976, 'epochs': 100, 'lr': 0.005399484409787433, 'batch_size': 32, 'optimizer': 'adam', 'gamma_type': 'manual', 'gamma': 0.016480446427978974}. Best is trial 0 with value: -4.010839262947069.\n",
      "[I 2025-10-07 19:41:35,448] Trial 1 finished with value: -4.01092731292504 and parameters: {'kernel': 'sigmoid', 'C': 0.262108787826544, 'epsilon': 0.03839629299804171, 'epochs': 250, 'lr': 0.000816845589476017, 'batch_size': 16, 'optimizer': 'rmsprop', 'gamma': 0.004809461967501573, 'coef0': 0.06505159298527952}. Best is trial 0 with value: -4.010839262947069.\n",
      "[I 2025-10-07 19:41:43,153] Trial 2 finished with value: -4.010899091733475 and parameters: {'kernel': 'rbf', 'C': 0.1963434157293333, 'epsilon': 0.23359635026261596, 'epochs': 250, 'lr': 0.00017541893487450815, 'batch_size': 64, 'optimizer': 'sgd', 'gamma_type': 'manual', 'gamma': 0.0054880470007660455}. Best is trial 0 with value: -4.010839262947069.\n",
      "[I 2025-10-07 19:41:45,031] Trial 3 finished with value: -4.008869541962301 and parameters: {'kernel': 'linear', 'C': 6.218704727769076, 'epsilon': 0.697828126512603, 'epochs': 100, 'lr': 0.0002465844721448739, 'batch_size': 64, 'optimizer': 'sgd'}. Best is trial 3 with value: -4.008869541962301.\n",
      "[I 2025-10-07 19:42:06,851] Trial 4 finished with value: -4.010937842967244 and parameters: {'kernel': 'sigmoid', 'C': 0.16736010167825777, 'epsilon': 0.9413993046829938, 'epochs': 400, 'lr': 0.00024970737145052745, 'batch_size': 32, 'optimizer': 'sgd', 'gamma': 0.02715581955282941, 'coef0': 0.11586905952512971}. Best is trial 3 with value: -4.008869541962301.\n",
      "[I 2025-10-07 19:42:29,573] Trial 5 finished with value: -3.624238934919889 and parameters: {'kernel': 'linear', 'C': 0.8569331925053982, 'epsilon': 0.044706085467784894, 'epochs': 400, 'lr': 0.0018841476921545091, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 5 with value: -3.624238934919889.\n",
      "[I 2025-10-07 19:42:31,818] Trial 6 finished with value: -4.01085572601938 and parameters: {'kernel': 'linear', 'C': 0.11919481947918735, 'epsilon': 0.016435497475111333, 'epochs': 100, 'lr': 0.0018742210985555703, 'batch_size': 64, 'optimizer': 'rmsprop'}. Best is trial 5 with value: -3.624238934919889.\n",
      "[I 2025-10-07 19:42:43,432] Trial 7 finished with value: 0.47870854227843307 and parameters: {'kernel': 'poly', 'C': 61.53085601625307, 'epsilon': 0.41327654594663626, 'epochs': 350, 'lr': 0.005532496914298506, 'batch_size': 64, 'optimizer': 'rmsprop', 'degree': 3, 'gamma': 0.002755546207779663, 'coef0': 0.22793516254194168}. Best is trial 7 with value: 0.47870854227843307.\n",
      "[I 2025-10-07 19:42:52,092] Trial 8 finished with value: -3.986157747394169 and parameters: {'kernel': 'poly', 'C': 3.4059785435329952, 'epsilon': 0.06836314065022722, 'epochs': 150, 'lr': 0.0001736723715159316, 'batch_size': 32, 'optimizer': 'sgd', 'degree': 5, 'gamma': 7.076022085822011, 'coef0': 0.25178229582536416}. Best is trial 7 with value: 0.47870854227843307.\n",
      "[I 2025-10-07 19:42:57,749] Trial 9 finished with value: -3.9531163753162755 and parameters: {'kernel': 'linear', 'C': 6.740513796374042, 'epsilon': 0.10124137770478635, 'epochs': 100, 'lr': 0.0003608219327363787, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 7 with value: 0.47870854227843307.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:08,880] A new study created in memory with name: no-name-2211433b-cbf0-4bb2-a942-9b9120eee6b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ SVMRegressor Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.4787\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ kernel: poly\n",
      "  ‚Ä¢ C: 61.53085601625307\n",
      "  ‚Ä¢ epsilon: 0.41327654594663626\n",
      "  ‚Ä¢ epochs: 350\n",
      "  ‚Ä¢ lr: 0.005532496914298506\n",
      "  ‚Ä¢ batch_size: 64\n",
      "  ‚Ä¢ optimizer: rmsprop\n",
      "  ‚Ä¢ degree: 3\n",
      "  ‚Ä¢ gamma: 0.002755546207779663\n",
      "  ‚Ä¢ coef0: 0.22793516254194168\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.4957\n",
      "  ‚Ä¢ MSE: 2671.7217\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: DecisionTreeRegressor\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d33480ab344286a41e2a0b5d5a1409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:12,495] Trial 0 finished with value: 0.2663759162909659 and parameters: {'use_max_depth': False, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'mae'}. Best is trial 0 with value: 0.2663759162909659.\n",
      "[I 2025-10-07 19:43:13,883] Trial 1 finished with value: 0.3562406824906095 and parameters: {'use_max_depth': True, 'max_depth': 30, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'mae'}. Best is trial 1 with value: 0.3562406824906095.\n",
      "[I 2025-10-07 19:43:16,017] Trial 2 finished with value: 0.21182901831684497 and parameters: {'use_max_depth': False, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'mse'}. Best is trial 1 with value: 0.3562406824906095.\n",
      "[I 2025-10-07 19:43:20,828] Trial 3 finished with value: -0.04230998530012142 and parameters: {'use_max_depth': True, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'mae'}. Best is trial 1 with value: 0.3562406824906095.\n",
      "[I 2025-10-07 19:43:24,747] Trial 4 finished with value: 0.20750480766664636 and parameters: {'use_max_depth': True, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None, 'criterion': 'mse'}. Best is trial 1 with value: 0.3562406824906095.\n",
      "[I 2025-10-07 19:43:25,361] Trial 5 finished with value: 0.37964999520581033 and parameters: {'use_max_depth': True, 'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': 'log2', 'criterion': 'mse'}. Best is trial 5 with value: 0.37964999520581033.\n",
      "[I 2025-10-07 19:43:32,021] Trial 6 finished with value: 0.12307951333086675 and parameters: {'use_max_depth': False, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'mae'}. Best is trial 5 with value: 0.37964999520581033.\n",
      "[I 2025-10-07 19:43:33,125] Trial 7 finished with value: 0.36847705634685246 and parameters: {'use_max_depth': True, 'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'mse'}. Best is trial 5 with value: 0.37964999520581033.\n",
      "[I 2025-10-07 19:43:36,268] Trial 8 finished with value: 0.3322287213408104 and parameters: {'use_max_depth': False, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'mse'}. Best is trial 5 with value: 0.37964999520581033.\n",
      "[I 2025-10-07 19:43:38,570] Trial 9 finished with value: 0.024596345830648403 and parameters: {'use_max_depth': True, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'mae'}. Best is trial 5 with value: 0.37964999520581033.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:39,250] A new study created in memory with name: no-name-815e589b-c3ae-4220-95ba-57538f022cb3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ DecisionTreeRegressor Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.3796\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ use_max_depth: True\n",
      "  ‚Ä¢ max_depth: 30\n",
      "  ‚Ä¢ min_samples_split: 16\n",
      "  ‚Ä¢ min_samples_leaf: 10\n",
      "  ‚Ä¢ max_features: log2\n",
      "  ‚Ä¢ criterion: mse\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.3945\n",
      "  ‚Ä¢ MSE: 3207.8784\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: RandomForestRegressor\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d4f19834984df081f19456f4a57b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:40,300] Trial 0 finished with value: 0.47999813466117414 and parameters: {'use_max_depth': False, 'bootstrap': True, 'use_max_samples': True, 'max_samples': 0.5290418060840998, 'n_estimators': 440, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'absolute_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:40,831] Trial 1 finished with value: 0.45299599332015705 and parameters: {'use_max_depth': True, 'max_depth': 18, 'bootstrap': True, 'use_max_samples': False, 'n_estimators': 230, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 0.8, 'criterion': 'absolute_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:41,428] Trial 2 finished with value: 0.45792040672684686 and parameters: {'use_max_depth': True, 'max_depth': 19, 'bootstrap': False, 'n_estimators': 230, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'absolute_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:42,651] Trial 3 finished with value: 0.44015931184577073 and parameters: {'use_max_depth': False, 'bootstrap': False, 'n_estimators': 450, 'min_samples_split': 13, 'min_samples_leaf': 10, 'max_features': 0.6, 'criterion': 'absolute_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:42,793] Trial 4 finished with value: 0.4050579411997348 and parameters: {'use_max_depth': True, 'max_depth': 29, 'bootstrap': False, 'n_estimators': 40, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': 1.0, 'criterion': 'squared_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:43,157] Trial 5 finished with value: 0.4733943858428189 and parameters: {'use_max_depth': True, 'max_depth': 44, 'bootstrap': True, 'use_max_samples': False, 'n_estimators': 170, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'absolute_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:43,490] Trial 6 finished with value: 0.47831438832369666 and parameters: {'use_max_depth': False, 'bootstrap': True, 'use_max_samples': True, 'max_samples': 0.8182052056318903, 'n_estimators': 160, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_features': 1.0, 'criterion': 'squared_error'}. Best is trial 0 with value: 0.47999813466117414.\n",
      "[I 2025-10-07 19:43:43,992] Trial 7 finished with value: 0.48016444657240887 and parameters: {'use_max_depth': True, 'max_depth': 34, 'bootstrap': True, 'use_max_samples': False, 'n_estimators': 270, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': 0.6, 'criterion': 'squared_error'}. Best is trial 7 with value: 0.48016444657240887.\n",
      "[I 2025-10-07 19:43:44,884] Trial 8 finished with value: 0.356684232934117 and parameters: {'use_max_depth': True, 'max_depth': 15, 'bootstrap': False, 'n_estimators': 480, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 1.0, 'criterion': 'squared_error'}. Best is trial 7 with value: 0.48016444657240887.\n",
      "[I 2025-10-07 19:43:45,168] Trial 9 finished with value: 0.47209193653415227 and parameters: {'use_max_depth': True, 'max_depth': 33, 'bootstrap': True, 'use_max_samples': False, 'n_estimators': 120, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'squared_error'}. Best is trial 7 with value: 0.48016444657240887.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:45,671] A new study created in memory with name: no-name-e1b09a24-2b4b-4367-8069-a87a12b3799b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ RandomForestRegressor Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.4802\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ use_max_depth: True\n",
      "  ‚Ä¢ max_depth: 34\n",
      "  ‚Ä¢ bootstrap: True\n",
      "  ‚Ä¢ use_max_samples: False\n",
      "  ‚Ä¢ n_estimators: 270\n",
      "  ‚Ä¢ min_samples_split: 17\n",
      "  ‚Ä¢ min_samples_leaf: 9\n",
      "  ‚Ä¢ max_features: 0.6\n",
      "  ‚Ä¢ criterion: squared_error\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.4797\n",
      "  ‚Ä¢ MSE: 2756.4608\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: KNNRegressor\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdcaee7f49e42cbbdf5a0ee6defd1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:45,718] Trial 0 finished with value: 0.42685542815532496 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.42685542815532496.\n",
      "[I 2025-10-07 19:43:45,725] Trial 1 finished with value: 0.38145251845799466 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'cosine'}. Best is trial 0 with value: 0.42685542815532496.\n",
      "[I 2025-10-07 19:43:45,757] Trial 2 finished with value: 0.40184902691365276 and parameters: {'n_neighbors': 42, 'weights': 'uniform', 'metric': 'cosine'}. Best is trial 0 with value: 0.42685542815532496.\n",
      "[I 2025-10-07 19:43:45,840] Trial 3 finished with value: 0.43649141112727463 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'cosine'}. Best is trial 3 with value: 0.43649141112727463.\n",
      "[I 2025-10-07 19:43:45,859] Trial 4 finished with value: 0.383199940632142 and parameters: {'n_neighbors': 23, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 3 with value: 0.43649141112727463.\n",
      "[I 2025-10-07 19:43:45,870] Trial 5 finished with value: 0.40741646720249003 and parameters: {'n_neighbors': 31, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 3 with value: 0.43649141112727463.\n",
      "[I 2025-10-07 19:43:45,881] Trial 6 finished with value: 0.458366791825463 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'cosine'}. Best is trial 6 with value: 0.458366791825463.\n",
      "[I 2025-10-07 19:43:45,889] Trial 7 finished with value: 0.3322931226835779 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 6 with value: 0.458366791825463.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:45,926] A new study created in memory with name: no-name-ff644c92-4181-4dcc-9da0-e7a6a030e02d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:45,901] Trial 8 finished with value: 0.41269373976168233 and parameters: {'n_neighbors': 28, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 6 with value: 0.458366791825463.\n",
      "[I 2025-10-07 19:43:45,910] Trial 9 finished with value: 0.4163773702474983 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'metric': 'cosine'}. Best is trial 6 with value: 0.458366791825463.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ KNNRegressor Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.4584\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ n_neighbors: 16\n",
      "  ‚Ä¢ weights: distance\n",
      "  ‚Ä¢ metric: cosine\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Performance:\n",
      "  ‚Ä¢ R¬≤ Score: 0.4584\n",
      "  ‚Ä¢ MSE: 2869.6549\n",
      "\n",
      "======================================================================\n",
      "üîç CLASSIFICATION MODELS - HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: LogisticRegression\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96389aec1c424f0c9c47d1baaa261bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:43:51,392] Trial 0 finished with value: 0.9666666666666667 and parameters: {'epochs': 200, 'lr': 0.07114476009343425, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:43:57,000] Trial 1 finished with value: 0.8333333333333334 and parameters: {'epochs': 400, 'lr': 0.00011527987128232407, 'batch_size': 16, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:43:59,576] Trial 2 finished with value: 0.7 and parameters: {'epochs': 250, 'lr': 0.0007476312062252305, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:01,219] Trial 3 finished with value: 0.9666666666666667 and parameters: {'epochs': 300, 'lr': 0.005987474910461402, 'batch_size': 32, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:02,899] Trial 4 finished with value: 0.7666666666666667 and parameters: {'epochs': 200, 'lr': 0.00019634341572933326, 'batch_size': 16, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:03,586] Trial 5 finished with value: 0.3 and parameters: {'epochs': 350, 'lr': 0.0008612579192594886, 'batch_size': 128, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:04,462] Trial 6 finished with value: 0.9666666666666667 and parameters: {'epochs': 300, 'lr': 0.058293845429947415, 'batch_size': 128, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:05,156] Trial 7 finished with value: 0.36666666666666664 and parameters: {'epochs': 200, 'lr': 0.0006963114377829289, 'batch_size': 64, 'optimizer': 'adam'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:05,299] Trial 8 finished with value: 0.9666666666666667 and parameters: {'epochs': 50, 'lr': 0.02795015916508337, 'batch_size': 64, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.9666666666666667.\n",
      "[I 2025-10-07 19:44:06,024] Trial 9 finished with value: 0.3 and parameters: {'epochs': 350, 'lr': 0.0009833181933644897, 'batch_size': 128, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9666666666666667.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:44:08,204] A new study created in memory with name: no-name-246b8199-0fdb-45cf-9229-c8d87fb35aa6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ LogisticRegression Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.9667\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ epochs: 200\n",
      "  ‚Ä¢ lr: 0.07114476009343425\n",
      "  ‚Ä¢ batch_size: 16\n",
      "  ‚Ä¢ optimizer: sgd\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Accuracy: 1.0000\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: SVMClassifier\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b505661f387d4e3cbca70c037c3e6f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:44:14,963] Trial 0 finished with value: 0.7 and parameters: {'kernel': 'rbf', 'C': 0.2938027938703535, 'epochs': 150, 'lr': 0.00013066739238053285, 'batch_size': 16, 'optimizer': 'sgd', 'gamma': 'scale'}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-10-07 19:44:21,579] Trial 1 finished with value: 0.7 and parameters: {'kernel': 'poly', 'C': 0.7476312062252299, 'epochs': 350, 'lr': 0.00019010245319870352, 'batch_size': 64, 'optimizer': 'adam', 'gamma': 'scale', 'degree': 4, 'coef0': 0.17052412368729153}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-10-07 19:44:22,635] Trial 2 finished with value: 0.7666666666666667 and parameters: {'kernel': 'poly', 'C': 0.8200518402245829, 'epochs': 100, 'lr': 0.0023359635026261607, 'batch_size': 64, 'optimizer': 'sgd', 'gamma': 'scale', 'degree': 4, 'coef0': 0.5467102793432796}. Best is trial 2 with value: 0.7666666666666667.\n",
      "[I 2025-10-07 19:44:30,052] Trial 3 finished with value: 1.0 and parameters: {'kernel': 'rbf', 'C': 48.35952776465949, 'epochs': 350, 'lr': 0.0069782812651260325, 'batch_size': 32, 'optimizer': 'sgd', 'gamma': 'scale'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-07 19:44:40,326] Trial 4 finished with value: 0.3 and parameters: {'kernel': 'sigmoid', 'C': 0.16736010167825777, 'epochs': 500, 'lr': 0.0035033984911586884, 'batch_size': 64, 'optimizer': 'rmsprop', 'gamma': 'auto', 'coef0': 0.11586905952512971}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-07 19:44:45,559] Trial 5 finished with value: 0.7 and parameters: {'kernel': 'linear', 'C': 0.8569331925053982, 'epochs': 200, 'lr': 0.002878805718308925, 'batch_size': 32, 'optimizer': 'rmsprop'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-07 19:44:49,286] Trial 6 finished with value: 0.36666666666666664 and parameters: {'kernel': 'rbf', 'C': 1.9170041589170652, 'epochs': 100, 'lr': 0.00016435497475111326, 'batch_size': 32, 'optimizer': 'sgd', 'gamma': 'auto'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-07 19:45:23,120] Trial 7 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 61.53085601625307, 'epochs': 450, 'lr': 0.0018484491720988621, 'batch_size': 16, 'optimizer': 'adam', 'gamma': 'scale', 'degree': 2, 'coef0': 0.22793516254194168}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-07 19:45:28,330] Trial 8 finished with value: 0.9666666666666667 and parameters: {'kernel': 'poly', 'C': 3.4059785435329952, 'epochs': 250, 'lr': 0.00027810936979265544, 'batch_size': 64, 'optimizer': 'rmsprop', 'gamma': 'auto', 'degree': 5, 'coef0': 0.25178229582536416}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-07 19:45:35,924] Trial 9 finished with value: 0.6333333333333333 and parameters: {'kernel': 'linear', 'C': 6.740513796374042, 'epochs': 300, 'lr': 0.00012675278269816303, 'batch_size': 32, 'optimizer': 'rmsprop'}. Best is trial 3 with value: 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:46,192] A new study created in memory with name: no-name-f57f6b66-117f-4c1b-bf29-d6319b4bc2dc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ SVMClassifier Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 1.0000\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ kernel: rbf\n",
      "  ‚Ä¢ C: 48.35952776465949\n",
      "  ‚Ä¢ epochs: 350\n",
      "  ‚Ä¢ lr: 0.0069782812651260325\n",
      "  ‚Ä¢ batch_size: 32\n",
      "  ‚Ä¢ optimizer: sgd\n",
      "  ‚Ä¢ gamma: scale\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Accuracy: 1.0000\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: DecisionTreeClassifier\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e89ccf50bd4612bc87b0277d901faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:46,557] Trial 0 finished with value: 1.0 and parameters: {'use_max_depth': False, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': None, 'criterion': 'gini'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:46,728] Trial 1 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 30, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:46,932] Trial 2 finished with value: 1.0 and parameters: {'use_max_depth': False, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:47,109] Trial 3 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:47,350] Trial 4 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None, 'criterion': 'entropy'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:47,436] Trial 5 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:47,663] Trial 6 finished with value: 1.0 and parameters: {'use_max_depth': False, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'gini'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:48,045] Trial 7 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:48,183] Trial 8 finished with value: 0.9666666666666667 and parameters: {'use_max_depth': False, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy'}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:48,507] A new study created in memory with name: no-name-4250d0ff-f355-4352-9b51-1e4dcb4929a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:48,336] Trial 9 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 0 with value: 1.0.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DecisionTreeClassifier Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 1.0000\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ use_max_depth: False\n",
      "  ‚Ä¢ min_samples_split: 15\n",
      "  ‚Ä¢ min_samples_leaf: 6\n",
      "  ‚Ä¢ max_features: None\n",
      "  ‚Ä¢ criterion: gini\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Accuracy: 1.0000\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: RandomForestClassifier\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71f24e52e99441daf9bbae81e7cd8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:49,322] Trial 0 finished with value: 1.0 and parameters: {'use_max_depth': False, 'n_estimators': 370, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:49,638] Trial 1 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 13, 'n_estimators': 160, 'criterion': 'gini', 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 0.6, 'bootstrap': True}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:49,763] Trial 2 finished with value: 1.0 and parameters: {'use_max_depth': False, 'n_estimators': 30, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:49,886] Trial 3 finished with value: 1.0 and parameters: {'use_max_depth': False, 'n_estimators': 20, 'criterion': 'gini', 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 0.6, 'bootstrap': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:50,168] Trial 4 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 47, 'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:50,607] Trial 5 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 50, 'n_estimators': 390, 'criterion': 'gini', 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:51,108] Trial 6 finished with value: 0.9666666666666667 and parameters: {'use_max_depth': True, 'max_depth': 7, 'n_estimators': 160, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 0.6, 'bootstrap': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:51,423] Trial 7 finished with value: 0.9666666666666667 and parameters: {'use_max_depth': False, 'n_estimators': 220, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 0.8, 'bootstrap': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:51,579] Trial 8 finished with value: 0.9666666666666667 and parameters: {'use_max_depth': True, 'max_depth': 18, 'n_estimators': 90, 'criterion': 'gini', 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 0.8, 'bootstrap': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:51,927] Trial 9 finished with value: 1.0 and parameters: {'use_max_depth': True, 'max_depth': 15, 'n_estimators': 220, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:52,554] A new study created in memory with name: no-name-071858d9-1f0d-4ea2-a0a0-d2026e2913d4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ RandomForestClassifier Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 1.0000\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ use_max_depth: False\n",
      "  ‚Ä¢ n_estimators: 370\n",
      "  ‚Ä¢ criterion: gini\n",
      "  ‚Ä¢ min_samples_split: 4\n",
      "  ‚Ä¢ min_samples_leaf: 1\n",
      "  ‚Ä¢ max_features: sqrt\n",
      "  ‚Ä¢ bootstrap: True\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Accuracy: 1.0000\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: BaggingClassifier\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f014e5b68e1948f78ed21a5282a9e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:45:55,643] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 40, 'max_samples': 0.9753571532049581, 'max_features': 0.8659969709057025, 'bootstrap': True, 'bootstrap_features': True}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:45:57,763] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 90, 'max_samples': 0.8005575058716043, 'max_features': 0.8540362888980227, 'bootstrap': False, 'bootstrap_features': True}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:00,037] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 20, 'max_samples': 0.5917022549267169, 'max_features': 0.6521211214797689, 'bootstrap': True, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:02,374] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 20, 'max_samples': 0.6460723242676091, 'max_features': 0.6831809216468459, 'bootstrap': False, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:04,633] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 60, 'max_samples': 0.5232252063599989, 'max_features': 0.8037724259507192, 'bootstrap': True, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:06,976] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 90, 'max_samples': 0.6523068845866853, 'max_features': 0.5488360570031919, 'bootstrap': True, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:09,105] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 10, 'max_samples': 0.954660201039391, 'max_features': 0.6293899908000085, 'bootstrap': True, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:11,689] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 20, 'max_samples': 0.9847923138822793, 'max_features': 0.8875664116805573, 'bootstrap': True, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:14,312] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 10, 'max_samples': 0.5979914312095727, 'max_features': 0.522613644455269, 'bootstrap': False, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:18,054] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 40, 'max_samples': 0.6404672548436904, 'max_features': 0.7713480415791243, 'bootstrap': False, 'bootstrap_features': False}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:21,618] A new study created in memory with name: no-name-39ab265d-6f4f-4fea-af35-a25af274f8c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ BaggingClassifier Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 1.0000\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ n_estimators: 40\n",
      "  ‚Ä¢ max_samples: 0.9753571532049581\n",
      "  ‚Ä¢ max_features: 0.8659969709057025\n",
      "  ‚Ä¢ bootstrap: True\n",
      "  ‚Ä¢ bootstrap_features: True\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Accuracy: 1.0000\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: KNNClassifier\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c56e834cdf4b2aab8c1744009485c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:21,875] Trial 0 finished with value: 1.0 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:21,914] Trial 1 finished with value: 0.9666666666666667 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'cosine'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,194] Trial 2 finished with value: 0.9666666666666667 and parameters: {'n_neighbors': 42, 'weights': 'uniform', 'metric': 'cosine'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,299] Trial 3 finished with value: 1.0 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'cosine'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,637] Trial 4 finished with value: 1.0 and parameters: {'n_neighbors': 23, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,783] Trial 5 finished with value: 1.0 and parameters: {'n_neighbors': 31, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,855] Trial 6 finished with value: 1.0 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'cosine'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,871] Trial 7 finished with value: 1.0 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:22,990] Trial 8 finished with value: 1.0 and parameters: {'n_neighbors': 28, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-07 19:46:23,172] Trial 9 finished with value: 0.9666666666666667 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'metric': 'cosine'}. Best is trial 0 with value: 1.0.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ KNNClassifier Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 1.0000\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ n_neighbors: 19\n",
      "  ‚Ä¢ weights: uniform\n",
      "  ‚Ä¢ metric: euclidean\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:23,388] A new study created in memory with name: no-name-738277d9-bf65-412c-bebf-f7d8dbdb8903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Test Set Accuracy: 1.0000\n",
      "\n",
      "======================================================================\n",
      "üîç CLUSTERING MODELS - HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: KMeans\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe14eb62452045a489cb0366fd229987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:24,247] Trial 0 finished with value: 0.3492229946215037 and parameters: {'n_clusters': 9, 'max_iter': 1000, 'tol': 0.0008471801418819979, 'n_init': 14, 'init': 'k-means++'}. Best is trial 0 with value: 0.3492229946215037.\n",
      "[I 2025-10-07 19:46:24,475] Trial 1 finished with value: 0.8598282581279164 and parameters: {'n_clusters': 3, 'max_iter': 900, 'tol': 0.00025378155082656634, 'n_init': 16, 'init': 'random'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:25,314] Trial 2 finished with value: 0.3399124758701325 and parameters: {'n_clusters': 17, 'max_iter': 300, 'tol': 5.337032762603957e-06, 'n_init': 7, 'init': 'random'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:25,607] Trial 3 finished with value: 0.2645567328569067 and parameters: {'n_clusters': 10, 'max_iter': 300, 'tol': 0.0002801635158716264, 'n_init': 7, 'init': 'random'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:26,582] Trial 4 finished with value: 0.19876883030341314 and parameters: {'n_clusters': 10, 'max_iter': 800, 'tol': 6.290644294586145e-06, 'n_init': 13, 'init': 'k-means++'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:28,499] Trial 5 finished with value: 0.3194908202615628 and parameters: {'n_clusters': 13, 'max_iter': 200, 'tol': 1.8205657658407268e-06, 'n_init': 20, 'init': 'k-means++'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:29,156] Trial 6 finished with value: 0.2935353538746936 and parameters: {'n_clusters': 7, 'max_iter': 100, 'tol': 0.0005456725485601478, 'n_init': 12, 'init': 'random'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:29,243] Trial 7 finished with value: 0.7221552744186077 and parameters: {'n_clusters': 2, 'max_iter': 1000, 'tol': 1.0842262717330169e-05, 'n_init': 15, 'init': 'random'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "[I 2025-10-07 19:46:30,318] Trial 8 finished with value: 0.19807874693936925 and parameters: {'n_clusters': 12, 'max_iter': 200, 'tol': 0.00755681014127443, 'n_init': 17, 'init': 'k-means++'}. Best is trial 1 with value: 0.8598282581279164.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:31,152] A new study created in memory with name: no-name-c9c2568e-187f-41ef-85d2-f75b3534baf6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:31,011] Trial 9 finished with value: 0.32709947546691487 and parameters: {'n_clusters': 13, 'max_iter': 1000, 'tol': 2.259279742015697e-06, 'n_init': 8, 'init': 'random'}. Best is trial 1 with value: 0.8598282581279164.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ KMeans Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.8598\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ n_clusters: 3\n",
      "  ‚Ä¢ max_iter: 900\n",
      "  ‚Ä¢ tol: 0.00025378155082656634\n",
      "  ‚Ä¢ n_init: 16\n",
      "  ‚Ä¢ init: random\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Silhouette Score: 0.8598\n",
      "\n",
      "======================================================================\n",
      "üöÄ Running: DBSCAN\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f8f43b4ad14c06af11f5664f8d2020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 19:46:31,545] Trial 0 finished with value: 0.5381981195209474 and parameters: {'eps': 1.9352465823520764, 'min_samples': 20, 'metric': 'euclidean'}. Best is trial 0 with value: 0.5381981195209474.\n",
      "[I 2025-10-07 19:46:31,751] Trial 1 finished with value: -0.42001988702941406 and parameters: {'eps': 0.864373149647393, 'min_samples': 3, 'metric': 'euclidean'}. Best is trial 0 with value: 0.5381981195209474.\n",
      "[I 2025-10-07 19:46:31,838] Trial 2 finished with value: -1.0 and parameters: {'eps': 0.200864022049432, 'min_samples': 20, 'metric': 'euclidean'}. Best is trial 0 with value: 0.5381981195209474.\n",
      "[I 2025-10-07 19:46:31,961] Trial 3 finished with value: -0.153518615631543 and parameters: {'eps': 0.9986820982818257, 'min_samples': 7, 'metric': 'euclidean'}. Best is trial 0 with value: 0.5381981195209474.\n",
      "[I 2025-10-07 19:46:32,205] Trial 4 finished with value: 0.5329120807450787 and parameters: {'eps': 3.0980791841396598, 'min_samples': 4, 'metric': 'cosine'}. Best is trial 0 with value: 0.5381981195209474.\n",
      "[I 2025-10-07 19:46:32,331] Trial 5 finished with value: 0.647278666373425 and parameters: {'eps': 3.947362210825767, 'min_samples': 5, 'metric': 'manhattan'}. Best is trial 5 with value: 0.647278666373425.\n",
      "[I 2025-10-07 19:46:32,662] Trial 6 finished with value: 0.5329120807450787 and parameters: {'eps': 3.0769697743170483, 'min_samples': 5, 'metric': 'cosine'}. Best is trial 5 with value: 0.647278666373425.\n",
      "[I 2025-10-07 19:46:32,847] Trial 7 finished with value: 0.647278666373425 and parameters: {'eps': 4.06114700577066, 'min_samples': 7, 'metric': 'manhattan'}. Best is trial 5 with value: 0.647278666373425.\n",
      "[I 2025-10-07 19:46:32,948] Trial 8 finished with value: -0.44437319452632845 and parameters: {'eps': 0.6979873507394163, 'min_samples': 11, 'metric': 'manhattan'}. Best is trial 5 with value: 0.647278666373425.\n",
      "[I 2025-10-07 19:46:33,080] Trial 9 finished with value: 0.6399410774679282 and parameters: {'eps': 3.346359193334512, 'min_samples': 7, 'metric': 'manhattan'}. Best is trial 5 with value: 0.647278666373425.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DBSCAN Optimization Complete!\n",
      "======================================================================\n",
      "Best Score: 0.6473\n",
      "\n",
      "Best Hyperparameters:\n",
      "  ‚Ä¢ eps: 3.947362210825767\n",
      "  ‚Ä¢ min_samples: 5\n",
      "  ‚Ä¢ metric: manhattan\n",
      "\n",
      "Total Trials: 10\n",
      "======================================================================\n",
      "\n",
      "üìä Test Set Silhouette Score: 0.6473\n",
      "\n",
      "======================================================================\n",
      "üìã HYPERPARAMETER TUNING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üîπ REGRESSION MODELS:\n",
      "----------------------------------------------------------------------\n",
      "LinearRegression               | R¬≤: 0.4526 | MSE:  2900.19\n",
      "RidgeRegression                | R¬≤: 0.2928 | MSE:  3746.74\n",
      "LassoRegression                | R¬≤: 0.2898 | MSE:  3762.52\n",
      "SVMRegressor                   | R¬≤: 0.4957 | MSE:  2671.72\n",
      "DecisionTreeRegressor          | R¬≤: 0.3945 | MSE:  3207.88\n",
      "RandomForestRegressor          | R¬≤: 0.4797 | MSE:  2756.46\n",
      "KNNRegressor                   | R¬≤: 0.4584 | MSE:  2869.65\n",
      "\n",
      "üîπ CLASSIFICATION MODELS:\n",
      "----------------------------------------------------------------------\n",
      "LogisticRegression             | Accuracy: 1.0000\n",
      "SVMClassifier                  | Accuracy: 1.0000\n",
      "DecisionTreeClassifier         | Accuracy: 1.0000\n",
      "RandomForestClassifier         | Accuracy: 1.0000\n",
      "BaggingClassifier              | Accuracy: 1.0000\n",
      "KNNClassifier                  | Accuracy: 1.0000\n",
      "\n",
      "üîπ CLUSTERING MODELS:\n",
      "----------------------------------------------------------------------\n",
      "KMeans                         | Silhouette: 0.8598\n",
      "DBSCAN                         | Silhouette: 0.6473\n",
      "\n",
      "======================================================================\n",
      "\n",
      "‚úÖ ALL HYPERPARAMETER TUNING COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run Optuna Hyperparameter Optimization for ALL Lightning ML Models\n",
    "===================================================================\n",
    "Complete notebook-ready script with all functions included\n",
    "\"\"\"\n",
    "\n",
    "import optuna\n",
    "import inspect\n",
    "from sklearn.datasets import load_iris, load_diabetes, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score, mean_squared_error, accuracy_score, r2_score\n",
    "\n",
    "# Import all model classes\n",
    "from lightning_ml.regression import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    RidgeRegression,\n",
    "    LassoRegression\n",
    ")\n",
    "\n",
    "from lightning_ml.tree import (\n",
    "    DecisionTreeClassifier,\n",
    "    DecisionTreeRegressor\n",
    ")\n",
    "\n",
    "from lightning_ml.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    "    BaggingClassifier\n",
    ")\n",
    "\n",
    "from lightning_ml.svm import (\n",
    "    SVMClassifier,\n",
    "    SVMRegressor\n",
    ")\n",
    "\n",
    "from lightning_ml.neighbours import (\n",
    "    KNNClassifier,\n",
    "    KNNRegressor\n",
    ")\n",
    "\n",
    "from lightning_ml.cluster import (\n",
    "    KMeans,\n",
    "    DBSCAN\n",
    ")\n",
    "\n",
    "# Import suggest functions from your optuna_optimizer module\n",
    "from lightning_ml.optuna_optimizer import (\n",
    "    suggest_linear_regression_params,\n",
    "    suggest_logistic_regression_params,\n",
    "    suggest_ridge_regression_params,\n",
    "    suggest_lasso_regression_params,\n",
    "    suggest_svm_classifier_params,\n",
    "    suggest_svm_regressor_params,\n",
    "    suggest_decision_tree_classifier_params,\n",
    "    suggest_decision_tree_regressor_params,\n",
    "    suggest_random_forest_classifier_params,\n",
    "    suggest_random_forest_regressor_params,\n",
    "    suggest_bagging_classifier_params,\n",
    "    suggest_knn_classifier_params,\n",
    "    suggest_knn_regressor_params,\n",
    "    suggest_kmeans_params,\n",
    "    suggest_dbscan_params,\n",
    "    suggest_apriori_params\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def filter_model_params(params, model_class):\n",
    "    \"\"\"Filter parameters to only include those accepted by the model\"\"\"\n",
    "    sig = inspect.signature(model_class.__init__)\n",
    "    valid_params = set(sig.parameters.keys()) - {'self'}\n",
    "    filtered = {k: v for k, v in params.items() if k in valid_params}\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def (model_class, suggest_params_func, X_train, y_train, \n",
    "                     X_test, y_test, metric='accuracy', n_trials=10, \n",
    "                     timeout=None, direction='maximize'):\n",
    "    \"\"\"Create and run Optuna optimization\"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = suggest_params_func(trial)\n",
    "        model_params = filter_model_params(params, model_class)\n",
    "        \n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        if metric == 'accuracy':\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "        elif metric == 'mse':\n",
    "            score = -mean_squared_error(y_test, y_pred)\n",
    "        elif metric == 'r2':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {metric}\")\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction=direction,\n",
    "        sampler=optuna.samplers.TPESampler(seed=42)\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n",
    "    \n",
    "    best_params = filter_model_params(study.best_params, model_class)\n",
    "    best_model = model_class(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    return best_model, study\n",
    "\n",
    "\n",
    "def print_optimization_results(study, model_name):\n",
    "    \"\"\"Print optimization results\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ {model_name} Optimization Complete!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Best Score: {study.best_value:.4f}\")\n",
    "    print(f\"\\nBest Hyperparameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "    print(f\"\\nTotal Trials: {len(study.trials)}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# MODEL GROUPS\n",
    "# =====================================================================\n",
    "regression_models = {\n",
    "    \"LinearRegression\": (LinearRegression, suggest_linear_regression_params),\n",
    "    \"RidgeRegression\": (RidgeRegression, suggest_ridge_regression_params),\n",
    "    \"LassoRegression\": (LassoRegression, suggest_lasso_regression_params),\n",
    "    \"SVMRegressor\": (SVMRegressor, suggest_svm_regressor_params),\n",
    "    \"DecisionTreeRegressor\": (DecisionTreeRegressor, suggest_decision_tree_regressor_params),\n",
    "    \"RandomForestRegressor\": (RandomForestRegressor, suggest_random_forest_regressor_params),\n",
    "    \"KNNRegressor\": (KNNRegressor, suggest_knn_regressor_params),\n",
    "}\n",
    "\n",
    "classification_models = {\n",
    "    \"LogisticRegression\": (LogisticRegression, suggest_logistic_regression_params),\n",
    "    \"SVMClassifier\": (SVMClassifier, suggest_svm_classifier_params),\n",
    "    \"DecisionTreeClassifier\": (DecisionTreeClassifier, suggest_decision_tree_classifier_params),\n",
    "    \"RandomForestClassifier\": (RandomForestClassifier, suggest_random_forest_classifier_params),\n",
    "    \"BaggingClassifier\": (BaggingClassifier, suggest_bagging_classifier_params),\n",
    "    \"KNNClassifier\": (KNNClassifier, suggest_knn_classifier_params),\n",
    "}\n",
    "\n",
    "clustering_models = {\n",
    "    \"KMeans\": (KMeans, suggest_kmeans_params),\n",
    "    \"DBSCAN\": (DBSCAN, suggest_dbscan_params),\n",
    "}\n",
    "\n",
    "apriori_model = {\n",
    "    \"Apriori\": (suggest_apriori_params)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# RUNNER FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def run_all_regressors(n_trials=10, timeout=120):\n",
    "    \"\"\"Run hyperparameter tuning for all regression models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîç REGRESSION MODELS - HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {}\n",
    "    for name, (cls, suggest_func) in regression_models.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üöÄ Running: {name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        try:\n",
    "            best_model, study = create_optimizer(\n",
    "                model_class=cls,\n",
    "                suggest_params_func=suggest_func,\n",
    "                X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                metric='r2',\n",
    "                n_trials=n_trials,\n",
    "                timeout=timeout,\n",
    "                direction='maximize'\n",
    "            )\n",
    "            print_optimization_results(study, name)\n",
    "            \n",
    "            # Test the best model\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            test_r2 = r2_score(y_test, y_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_pred)\n",
    "            print(f\"üìä Test Set Performance:\")\n",
    "            print(f\"  ‚Ä¢ R¬≤ Score: {test_r2:.4f}\")\n",
    "            print(f\"  ‚Ä¢ MSE: {test_mse:.4f}\")\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': best_model,\n",
    "                'study': study,\n",
    "                'best_params': study.best_params,\n",
    "                'best_score': study.best_value,\n",
    "                'test_r2': test_r2,\n",
    "                'test_mse': test_mse\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå [ERROR] {name} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_all_classifiers(n_trials=10, timeout=120):\n",
    "    \"\"\"Run hyperparameter tuning for all classification models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîç CLASSIFICATION MODELS - HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {}\n",
    "    for name, (cls, suggest_func) in classification_models.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üöÄ Running: {name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        try:\n",
    "            best_model, study = create_optimizer(\n",
    "                model_class=cls,\n",
    "                suggest_params_func=suggest_func,\n",
    "                X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                metric='accuracy',\n",
    "                n_trials=n_trials,\n",
    "                timeout=timeout,\n",
    "                direction='maximize'\n",
    "            )\n",
    "            print_optimization_results(study, name)\n",
    "            \n",
    "            # Test the best model\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"üìä Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': best_model,\n",
    "                'study': study,\n",
    "                'best_params': study.best_params,\n",
    "                'best_score': study.best_value,\n",
    "                'test_accuracy': test_accuracy\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå [ERROR] {name} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_all_clustering(n_trials=10, timeout=120):\n",
    "    \"\"\"Run hyperparameter tuning for all clustering models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîç CLUSTERING MODELS - HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    X, y = make_blobs(n_samples=300, centers=3, n_features=2, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {}\n",
    "    for name, (cls, suggest_func) in clustering_models.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üöÄ Running: {name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        try:\n",
    "            def objective(trial):\n",
    "                params = suggest_func(trial)\n",
    "                model_params = filter_model_params(params, cls)\n",
    "                model = cls(**model_params)\n",
    "                model.fit(X_train)\n",
    "                labels = model.predict(X_test)\n",
    "                \n",
    "                # Check if we have at least 2 clusters\n",
    "                if len(set(labels)) < 2:\n",
    "                    return -1.0\n",
    "                \n",
    "                score = silhouette_score(X_test, labels)\n",
    "                return score\n",
    "\n",
    "            study = optuna.create_study(\n",
    "                direction='maximize', \n",
    "                sampler=optuna.samplers.TPESampler(seed=42)\n",
    "            )\n",
    "            study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n",
    "\n",
    "            best_params = filter_model_params(study.best_params, cls)\n",
    "            best_model = cls(**best_params)\n",
    "            best_model.fit(X_train)\n",
    "            \n",
    "            print_optimization_results(study, name)\n",
    "            \n",
    "            # Test the best model\n",
    "            test_labels = best_model.predict(X_test)\n",
    "            if len(set(test_labels)) >= 2:\n",
    "                test_silhouette = silhouette_score(X_test, test_labels)\n",
    "                print(f\"üìä Test Set Silhouette Score: {test_silhouette:.4f}\")\n",
    "            else:\n",
    "                test_silhouette = -1.0\n",
    "                print(f\"‚ö†Ô∏è  Test Set: Only 1 cluster found\")\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': best_model,\n",
    "                'study': study,\n",
    "                'best_params': study.best_params,\n",
    "                'best_score': study.best_value,\n",
    "                'test_silhouette': test_silhouette\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå [ERROR] {name} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# SUMMARY FUNCTION\n",
    "# =====================================================================\n",
    "\n",
    "def print_summary(reg_results, cls_results, clu_results):\n",
    "    \"\"\"Print a summary of all results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìã HYPERPARAMETER TUNING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if reg_results:\n",
    "        print(\"\\nüîπ REGRESSION MODELS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for name, result in reg_results.items():\n",
    "            print(f\"{name:30s} | R¬≤: {result['test_r2']:6.4f} | MSE: {result['test_mse']:8.2f}\")\n",
    "    \n",
    "    if cls_results:\n",
    "        print(\"\\nüîπ CLASSIFICATION MODELS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for name, result in cls_results.items():\n",
    "            print(f\"{name:30s} | Accuracy: {result['test_accuracy']:6.4f}\")\n",
    "    \n",
    "    if clu_results:\n",
    "        print(\"\\nüîπ CLUSTERING MODELS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for name, result in clu_results.items():\n",
    "            print(f\"{name:30s} | Silhouette: {result['test_silhouette']:6.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# MAIN EXECUTION\n",
    "# =====================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ö° LIGHTNING ML - HYPERPARAMETER OPTIMIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Running Optuna hyperparameter tuning for all models...\")\n",
    "    \n",
    "    # Run all optimizations\n",
    "    reg_results = run_all_regressors(n_trials=10, timeout=120)\n",
    "    cls_results = run_all_classifiers(n_trials=10, timeout=120)\n",
    "    clu_results = run_all_clustering(n_trials=10, timeout=120)\n",
    "    \n",
    "    # Print summary\n",
    "    print_summary(reg_results, cls_results, clu_results)\n",
    "    \n",
    "    print(\"\\n‚úÖ ALL HYPERPARAMETER TUNING COMPLETE!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e2c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 20:26:35,790] A new study created in memory with name: no-name-1071f3a5-8669-457e-9141-237dca0a944b\n",
      "[I 2025-10-07 20:26:35,794] Trial 0 finished with value: 0.0 and parameters: {'use_max_length': False, 'min_support': 0.3761512710010716, 'min_confidence': 0.5049574728808788, 'min_lift': 2.930724414633814}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-07 20:26:35,795] Trial 1 finished with value: 0.0 and parameters: {'use_max_length': False, 'min_support': 0.2961692239929821, 'min_confidence': 0.8137449152492808, 'min_lift': 4.414664410423578}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-07 20:26:35,798] Trial 2 finished with value: 0.0 and parameters: {'use_max_length': False, 'min_support': 0.47296720530573905, 'min_confidence': 0.5090553327247854, 'min_lift': 4.126752017259424}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-07 20:26:35,801] Trial 3 finished with value: 0.0 and parameters: {'use_max_length': True, 'max_length': 9, 'min_support': 0.026160278217937843, 'min_confidence': 0.333169983799656, 'min_lift': 4.586787937094195}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-07 20:26:35,803] Trial 4 finished with value: 1.5333333333333334 and parameters: {'use_max_length': True, 'max_length': 2, 'min_support': 0.2400655810594626, 'min_confidence': 0.6030159423476812, 'min_lift': 1.1844501700152854}. Best is trial 4 with value: 1.5333333333333334.\n",
      "[I 2025-10-07 20:26:35,805] Trial 5 finished with value: 1.575 and parameters: {'use_max_length': False, 'min_support': 0.2519486041154769, 'min_confidence': 0.4322436828302182, 'min_lift': 1.4326634897921595}. Best is trial 5 with value: 1.575.\n",
      "[I 2025-10-07 20:26:35,807] Trial 6 finished with value: 0.0 and parameters: {'use_max_length': False, 'min_support': 0.1436578719178265, 'min_confidence': 0.5087063514794923, 'min_lift': 4.994618461761951}. Best is trial 5 with value: 1.575.\n",
      "[I 2025-10-07 20:26:35,810] Trial 7 finished with value: 0.0 and parameters: {'use_max_length': False, 'min_support': 0.1395241457046083, 'min_confidence': 0.14395469210306144, 'min_lift': 3.0496097801917856}. Best is trial 5 with value: 1.575.\n",
      "[I 2025-10-07 20:26:35,813] Trial 8 finished with value: 0.0 and parameters: {'use_max_length': True, 'max_length': 6, 'min_support': 0.47662880717152906, 'min_confidence': 0.5724760871415775, 'min_lift': 2.413316752412822}. Best is trial 5 with value: 1.575.\n",
      "[I 2025-10-07 20:26:35,816] Trial 9 finished with value: 0.0 and parameters: {'use_max_length': False, 'min_support': 0.21245130955476405, 'min_confidence': 0.25875414710771, 'min_lift': 3.2382159492829117}. Best is trial 5 with value: 1.575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚ö° LIGHTNING ML - APRIORI OPTUNA TEST\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Optuna optimization completed!\n",
      "Best parameters: {'use_max_length': False, 'min_support': 0.2519486041154769, 'min_confidence': 0.4322436828302182, 'min_lift': 1.4326634897921595}\n",
      "Best score (avg lift): 1.5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  # Clean output\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ö° LIGHTNING ML - APRIORI OPTUNA TEST\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    import optuna\n",
    "    from lightning_ml import Apriori  # Your Apriori class\n",
    "    from lightning_ml.optuna_optimizer import suggest_apriori_params  # Your Optuna parameter suggestion function\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Example transactional dataset\n",
    "    data = {\n",
    "        'Milk': [1, 0, 1, 1, 0, 1, 1, 0],\n",
    "        'Bread': [1, 1, 1, 1, 0, 0, 1, 1],\n",
    "        'Butter': [1, 0, 1, 0, 0, 1, 1, 0],\n",
    "        'Eggs': [0, 1, 1, 1, 1, 0, 1, 1],\n",
    "        'Cheese': [0, 0, 1, 1, 0, 1, 0, 0]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters using your function\n",
    "        params = suggest_apriori_params(trial)\n",
    "        model = Apriori(**params)\n",
    "        model.fit(df)\n",
    "        # Use avg lift of top 10 rules as objective\n",
    "        return model.score(df)\n",
    "\n",
    "    # Run Optuna study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, timeout=60)\n",
    "\n",
    "    print(\"\\n‚úÖ Optuna optimization completed!\")\n",
    "    print(f\"Best parameters: {study.best_params}\")\n",
    "    print(f\"Best score (avg lift): {study.best_value:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a5a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
