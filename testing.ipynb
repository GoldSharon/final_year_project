{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e39320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, make_regression, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84efd1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all models\n",
    "from lightning_ml import (\n",
    "    LinearRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    "    BaggingClassifier,\n",
    "    BaggingRegressor,\n",
    "    SVMClassifier,\n",
    "    SVMRegressor,\n",
    "    KNNClassifier,\n",
    "    KNNRegressor,\n",
    "    KMeans,\n",
    "    DBSCAN,\n",
    "    Apriori,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ad1278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==== Linear Regression ====\n",
      "Predictions: [ -7.8062716  39.81586   -29.448576  222.06757     6.6875525]\n",
      "R^2 Score: 0.9958655435892683\n",
      "\n",
      "==== Decision Tree Classifier ====\n",
      "Predictions: [1 2 0 1 1]\n",
      "Accuracy: 0.75\n",
      "\n",
      "==== Decision Tree Regressor ====\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== Decision Tree Regressor ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m dtr \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m \u001b[43mdtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_reg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m pred_dtr \u001b[38;5;241m=\u001b[39m dtr\u001b[38;5;241m.\u001b[39mpredict(X_test_reg)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, pred_dtr[:\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[1;32md:\\Auto_ML\\new_auto_ml\\lightning_ml\\tree.py:539\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, verbose)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding decision tree...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# Initialize and calculate feature importances\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importances_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_)\n",
      "File \u001b[1;32md:\\Auto_ML\\new_auto_ml\\lightning_ml\\tree.py:186\u001b[0m, in \u001b[0;36mDecisionTreeBase._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    182\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Create node\u001b[39;00m\n\u001b[0;32m    185\u001b[0m node \u001b[38;5;241m=\u001b[39m TreeNode(\n\u001b[1;32m--> 186\u001b[0m     impurity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_impurity\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    187\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39mn_samples\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Stopping criteria\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m depth \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m    192\u001b[0m    (n_samples \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m    193\u001b[0m    (node\u001b[38;5;241m.\u001b[39mimpurity \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m):\n",
      "File \u001b[1;32md:\\Auto_ML\\new_auto_ml\\lightning_ml\\tree.py:90\u001b[0m, in \u001b[0;36mDecisionTreeBase._calculate_impurity\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_calculate_impurity\u001b[39m(\u001b[38;5;28mself\u001b[39m, y: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate impurity (to be overridden by child classes).\"\"\"\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Device helper\n",
    "# =========================\n",
    "def get_device(name='cpu'):\n",
    "    if name == 'cuda' and torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif name == 'mps' and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device('cuda')  # Change to 'cuda' or 'mps' if available\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# =========================\n",
    "# Datasets\n",
    "# =========================\n",
    "# Classification\n",
    "X_cls, y_cls = make_classification(n_samples=200, n_features=10, n_informative=8,\n",
    "                                   n_redundant=2, n_classes=3, random_state=42)\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)\n",
    "\n",
    "# Regression\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=10, n_informative=8,\n",
    "                               noise=10.0, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "# Clustering\n",
    "X_clust, y_clust = make_blobs(n_samples=300, n_features=5, centers=3, random_state=42)\n",
    "\n",
    "# Apriori transaction data\n",
    "transaction_data = pd.DataFrame({\n",
    "    'milk': [1, 1, 0, 1, 1, 0, 1, 1],\n",
    "    'bread': [1, 1, 1, 0, 1, 1, 1, 0],\n",
    "    'butter': [1, 0, 1, 1, 0, 1, 1, 1],\n",
    "    'beer': [0, 1, 1, 0, 1, 0, 1, 0],\n",
    "    'eggs': [1, 1, 0, 1, 1, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# =========================\n",
    "# Linear Regression\n",
    "# =========================\n",
    "print(\"\\n==== Linear Regression ====\")\n",
    "lr = LinearRegression(device=device)\n",
    "lr.fit(X_train_reg, y_train_reg)\n",
    "pred_lr = lr.predict(X_test_reg)\n",
    "print(\"Predictions:\", pred_lr[:5])\n",
    "print(\"R^2 Score:\", lr.score(X_test_reg, y_test_reg))\n",
    "\n",
    "# =========================\n",
    "# Decision Tree\n",
    "# =========================\n",
    "print(\"\\n==== Decision Tree Classifier ====\")\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "dtc.fit(X_train_cls, y_train_cls)\n",
    "pred_dtc = dtc.predict(X_test_cls)\n",
    "print(\"Predictions:\", pred_dtc[:5])\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, pred_dtc))\n",
    "\n",
    "print(\"\\n==== Decision Tree Regressor ====\")\n",
    "dtr = DecisionTreeRegressor(max_depth=5)\n",
    "dtr.fit(X_train_reg, y_train_reg)\n",
    "pred_dtr = dtr.predict(X_test_reg)\n",
    "print(\"Predictions:\", pred_dtr[:5])\n",
    "print(\"R^2:\", dtr.score(X_test_reg, y_test_reg))\n",
    "\n",
    "# =========================\n",
    "# Random Forest\n",
    "# =========================\n",
    "print(\"\\n==== Random Forest Classifier ====\")\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "rfc.fit(X_train_cls, y_train_cls)\n",
    "pred_rfc = rfc.predict(X_test_cls)\n",
    "print(\"Predictions:\", pred_rfc[:5])\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, pred_rfc))\n",
    "\n",
    "print(\"\\n==== Random Forest Regressor ====\")\n",
    "rfr = RandomForestRegressor(n_estimators=10)\n",
    "rfr.fit(X_train_reg, y_train_reg)\n",
    "pred_rfr = rfr.predict(X_test_reg)\n",
    "print(\"Predictions:\", pred_rfr[:5])\n",
    "print(\"R^2:\", rfr.score(X_test_reg, y_test_reg))\n",
    "\n",
    "# =========================\n",
    "# Bagging\n",
    "# =========================\n",
    "print(\"\\n==== Bagging Classifier ====\")\n",
    "bag_cls = BaggingClassifier(n_estimators=10)\n",
    "bag_cls.fit(X_train_cls, y_train_cls)\n",
    "pred_bag_cls = bag_cls.predict(X_test_cls)\n",
    "print(\"Predictions:\", pred_bag_cls[:5])\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, pred_bag_cls))\n",
    "\n",
    "print(\"\\n==== Bagging Regressor ====\")\n",
    "bag_reg = BaggingRegressor(n_estimators=10)\n",
    "bag_reg.fit(X_train_reg, y_train_reg)\n",
    "pred_bag_reg = bag_reg.predict(X_test_reg)\n",
    "print(\"Predictions:\", pred_bag_reg[:5])\n",
    "print(\"R^2:\", bag_reg.score(X_test_reg, y_test_reg))\n",
    "\n",
    "# =========================\n",
    "# SVM\n",
    "# =========================\n",
    "print(\"\\n==== SVM Classifier ====\")\n",
    "svm_cls = SVMClassifier(kernel='rbf', epochs=50)\n",
    "svm_cls.fit(X_train_cls, y_train_cls)\n",
    "pred_svm_cls = svm_cls.predict(X_test_cls)\n",
    "print(\"Predictions:\", pred_svm_cls[:5])\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, pred_svm_cls))\n",
    "\n",
    "print(\"\\n==== SVM Regressor ====\")\n",
    "svm_reg = SVMRegressor(kernel='rbf', epochs=50)\n",
    "svm_reg.fit(X_train_reg, y_train_reg)\n",
    "pred_svm_reg = svm_reg.predict(X_test_reg)\n",
    "print(\"Predictions:\", pred_svm_reg[:5])\n",
    "print(\"R^2:\", svm_reg.score(X_test_reg, y_test_reg))\n",
    "\n",
    "# =========================\n",
    "# KNN\n",
    "# =========================\n",
    "print(\"\\n==== KNN Classifier ====\")\n",
    "knn_cls = KNNClassifier(n_neighbors=5)\n",
    "knn_cls.fit(X_train_cls, y_train_cls)\n",
    "pred_knn_cls = knn_cls.predict(X_test_cls)\n",
    "print(\"Predictions:\", pred_knn_cls[:5])\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, pred_knn_cls))\n",
    "\n",
    "print(\"\\n==== KNN Regressor ====\")\n",
    "knn_reg = KNNRegressor(n_neighbors=5)\n",
    "knn_reg.fit(X_train_reg, y_train_reg)\n",
    "pred_knn_reg = knn_reg.predict(X_test_reg)\n",
    "print(\"Predictions:\", pred_knn_reg[:5])\n",
    "print(\"R^2:\", knn_reg.score(X_test_reg, y_test_reg))\n",
    "\n",
    "# =========================\n",
    "# Clustering\n",
    "# =========================\n",
    "print(\"\\n==== KMeans ====\")\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_clust)\n",
    "labels_km = kmeans.predict(X_clust)\n",
    "print(\"Cluster labels:\", labels_km[:10])\n",
    "\n",
    "print(\"\\n==== DBSCAN ====\")\n",
    "dbscan = DBSCAN(eps=1.0, min_samples=5)\n",
    "labels_db = dbscan.fit_predict(X_clust)\n",
    "print(\"Cluster labels:\", labels_db[:10])\n",
    "\n",
    "print(\"\\n==== Agglomerative Clustering ====\")\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "labels_agg = agg.fit_predict(X_clust)\n",
    "print(\"Cluster labels:\", labels_agg[:10])\n",
    "\n",
    "# =========================\n",
    "# Apriori\n",
    "# =========================\n",
    "print(\"\\n==== Apriori ====\")\n",
    "apriori = Apriori(min_support=0.3, min_confidence=0.5)\n",
    "apriori.fit(transaction_data)\n",
    "print(\"Frequent Itemsets:\\n\", apriori.get_frequent_itemsets())\n",
    "print(\"Rules:\\n\", apriori.get_rules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b76ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
